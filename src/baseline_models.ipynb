{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89Q5h1M-iGtX"
   },
   "source": [
    "# Data preparation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# installed_packages = [\n",
    "#     \"opensmile\",\n",
    "#     \"librosa\",\n",
    "#     \"google\",\n",
    "#     \"treelib\",\n",
    "#     \"graphviz\",\n",
    "#     \"tensorflow\",\n",
    "# ]\n",
    "\n",
    "# for package in installed_packages:\n",
    "#     !pip install {package}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4pIIqhuk6Wdm"
   },
   "outputs": [],
   "source": [
    "import opensmile\n",
    "\n",
    "smile = opensmile.Smile(\n",
    "#     feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "#     feature_set=opensmile.FeatureSet.GeMAPSv01b,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9CnuzfCN6kxa",
    "outputId": "9c44bd5d-78f4-4762-d13f-fed963850c37"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "try:\n",
    "    files = glob.glob(\"../data/raw/RAVDESS/*/*.wav\")\n",
    "except:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    files = glob.glob(\"/content/gdrive/MyDrive/Colab Notebooks/IP/data/RAVDESS/*/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_emotion_mapping = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_to_positivity_mapping = {\n",
    "    \"neutral\": \"positive\",\n",
    "    \"calm\": \"positive\",\n",
    "    \"happy\": \"positive\",\n",
    "    \"sad\": \"negative\",\n",
    "    \"angry\": \"negative\",\n",
    "    \"fearful\": \"negative\",\n",
    "    \"disgust\": \"negative\",\n",
    "    \"surprised\": \"positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data reading and normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_data = smile.process_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_speech_data=(speech_data-speech_data.mean())/speech_data.std()\n",
    "normalised_speech_data.dropna(axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = [file_name_to_emotion_mapping[file.split(\"-\")[-5]] for file in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aikqCd3d7b6d"
   },
   "source": [
    "##### Splitting the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def perform_3_way_split(data, labels, split, seed=42):\n",
    "    assert np.sum(split) == 100, \"Split must be a 3-tuple with sum of 100\"\n",
    "    train, val, test = (num/100 for num in split)\n",
    "    \n",
    "    data_train_and_val, data_test, labels_train_and_val, labels_test = train_test_split(data, labels, test_size=test, random_state=seed, stratify=labels)\n",
    "    data_train, data_val, labels_train, labels_val = train_test_split(data_train_and_val, labels_train_and_val, test_size=val/(train+val), random_state=seed, stratify=labels_train_and_val)\n",
    "    return (data_train, data_val, data_test), (labels_train, labels_val, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3Wow_Uwc7qN9"
   },
   "outputs": [],
   "source": [
    "speeches = normalised_speech_data\n",
    "emotions = emotion_labels\n",
    "\n",
    "speeches_split, emotions_split = perform_3_way_split(speeches, emotions, (80,10,10), SEED)\n",
    "speeches_train, speeches_val, speeches_test = speeches_split\n",
    "emotions_train, emotions_val, emotions_test = emotions_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_binary_train = np.array([emotion_to_positivity_mapping[emotion] for emotion in emotions_train])\n",
    "emotions_binary_val = np.array([emotion_to_positivity_mapping[emotion] for emotion in emotions_val])\n",
    "emotions_binary_test = np.array([emotion_to_positivity_mapping[emotion] for emotion in emotions_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "id": "d7I594NDkO6c"
   },
   "outputs": [],
   "source": [
    "# Pandas dataframes keep the old indexing after sampling, but I need it to be sequential, thus, a reset for the index\n",
    "speeches_train.reset_index(drop=True, inplace=True)\n",
    "speeches_val.reset_index(drop=True, inplace=True)\n",
    "speeches_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mA9wf8eWZpm3",
    "outputId": "a28d0b18-7bd9-40a3-c17c-faa92c2d84e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(speeches_train)=1152\t\tlen(emotions_train)=1152\n",
      "len(speeches_val)=144\t\tlen(emotions_val)=144\n",
      "len(speeches_test)=144\t\tlen(emotions_test)=144\n",
      "Counter(emotions_train)=Counter({'angry': 154, 'happy': 154, 'calm': 154, 'sad': 154, 'disgust': 154, 'surprised': 153, 'fearful': 153, 'neutral': 76})\n",
      "Counter(emotions_val)=Counter({'fearful': 20, 'calm': 19, 'happy': 19, 'angry': 19, 'sad': 19, 'surprised': 19, 'disgust': 19, 'neutral': 10})\n",
      "Counter(emotions_test)=Counter({'surprised': 20, 'disgust': 19, 'angry': 19, 'fearful': 19, 'calm': 19, 'sad': 19, 'happy': 19, 'neutral': 10})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(f\"{len(speeches_train)=}\\t\\t{len(emotions_train)=}\")\n",
    "print(f\"{len(speeches_val)=}\\t\\t{len(emotions_val)=}\")\n",
    "print(f\"{len(speeches_test)=}\\t\\t{len(emotions_test)=}\")\n",
    "\n",
    "print(f\"{Counter(emotions_train)=}\")\n",
    "print(f\"{Counter(emotions_val)=}\")\n",
    "print(f\"{Counter(emotions_test)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXOYkvAbuT1"
   },
   "source": [
    "# Classifier comparison section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgQbyZBBb5mm"
   },
   "source": [
    "### Building classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe_knPbbb-vF"
   },
   "outputs": [],
   "source": [
    "from locale import Error\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_predict_and_score_classifier(classifier, data_train, data_val, labels_train, labels_val, label_set):\n",
    "    classifier.fit(data_train, labels_train)\n",
    "    results = {\"train\": {}, \"val\": {}}\n",
    "    \n",
    "    for set_type in [\"train\", \"val\"]:\n",
    "        if set_type == \"train\":\n",
    "            data = data_train\n",
    "            labels = labels_train\n",
    "        elif set_type == \"val\":\n",
    "            data = data_val\n",
    "            labels = labels_val\n",
    "        else:\n",
    "            raise Error(\"Undefined data set type\")\n",
    "\n",
    "        labels_predicted = classifier.predict(data)\n",
    "\n",
    "        results[set_type][\"predictions\"] = labels_predicted\n",
    "        results[set_type][\"accuracy\"] = metrics.accuracy_score(labels, labels_predicted)\n",
    "        results[set_type][\"precision\"] = metrics.precision_score(labels, labels_predicted, average=\"macro\", zero_division=1)\n",
    "        results[set_type][\"recall\"] = metrics.recall_score(labels, labels_predicted, average=\"macro\", zero_division=1)\n",
    "        results[set_type][\"F1\"] = metrics.f1_score(labels, labels_predicted, average=\"macro\", zero_division=1)\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_result_table(results):\n",
    "    first_key = list(results.keys())[0]\n",
    "    second_key = list(results[first_key].keys())[0]\n",
    "    table = pd.DataFrame(columns=[\"Classifier\", \"Set type\"] + list(results[first_key][second_key].keys()))\n",
    "    for classifier_name, classifier_data in results.items():\n",
    "        for set_type, set_metrics in classifier_data.items():\n",
    "              # Taken from (merging dicts) https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression-in-python\n",
    "            new_row = {\"Classifier\": classifier_name, \"Set type\": set_type} | set_metrics\n",
    "            table = table.append(new_row, ignore_index=True)\n",
    "    return table\n",
    "\n",
    "# def create_result_table(results):\n",
    "#     first_key = list(results.keys())[0]\n",
    "#     second_key = list(results[first_key].keys())[0]\n",
    "#     table = pd.DataFrame(columns=[\"Classifier\", \"Set type\"] + list(results[first_key][second_key].keys()))\n",
    "#     for classifier_name, classifier_data in results.items():\n",
    "#         for set_type, set_metrics in classifier_data.items():\n",
    "#               # Taken from (merging dicts) https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression-in-python\n",
    "#             new_row = pd.DataFrame({\"Classifier\": classifier_name, \"Set type\": set_type} | set_metrics)\n",
    "#             table = pd.concat([table, new_row], ignore_index=True)\n",
    "#     return table\n",
    "\n",
    "def calculate_f1_scores_by_class(labels_predicted, labels):\n",
    "    all_labels = sorted(list(set(labels)))\n",
    "    matrix_dimension = range(len(set(labels)))\n",
    "    matrix = metrics.confusion_matrix(labels, labels_predicted, labels=all_labels)\n",
    "\n",
    "    recalls = [matrix[index, index] / row_sum for index, row_sum in enumerate(np.sum(matrix, axis=1))]\n",
    "    precisions = [matrix[index, index] / column_sum for index, column_sum in enumerate(np.sum(matrix, axis=0))]\n",
    "\n",
    "    f1_scores = {label: {} for label in all_labels}\n",
    "    for index, label in enumerate(all_labels):\n",
    "        f1_scores[label] = 2 * (precisions[index] * recalls[index]) / (precisions[index] + recalls[index])\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmOWy_3elp_0"
   },
   "outputs": [],
   "source": [
    "# These parameters are repeated, so they are unwrapped while calling functions to reduce clutter\n",
    "multi_class_parameters = (speeches_train, speeches_val, emotions_train, emotions_val, set(emotions))\n",
    "binary_parameters = (speeches_train, speeches_val, emotions_binary_train, emotions_binary_val, set([\"positive\", \"negative\"]))\n",
    "initial_classifier_results = {}\n",
    "initial_classifier_results_binary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vbJMZzbEVeN"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results[\"dummy_classifier_most_frequent\"] = fit_predict_and_score_classifier(dummy_classifier_most_frequent, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP12BrTLkY0A"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results[\"dummy_classifier_stratified\"] = fit_predict_and_score_classifier(dummy_classifier_stratified, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFi7oHh1kqcF"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results[\"logistic_regression\"] = fit_predict_and_score_classifier(logistic_regression, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiN0CnX2ktST"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results[\"svc\"] = fit_predict_and_score_classifier(svc, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "68ytUVLHav6l",
    "outputId": "66b32dd9-2719-493c-8ac7-3261a8a4da8d"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results_table = create_result_table(initial_classifier_results)\n",
    "display(initial_classifier_results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XYuc7nRmNGd",
    "outputId": "7dc876a9-53df-4282-8600-0af2d9e98bbd"
   },
   "outputs": [],
   "source": [
    "f1_scores = calculate_f1_scores_by_class(initial_classifier_results[\"svc\"][\"val\"][\"predictions\"], emotions_val)\n",
    "for emotion, score in f1_scores.items():\n",
    "    print(f\"{emotion}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ZPCMAGy4opci",
    "outputId": "fab6fd7c-b687-4747-fc6b-db022f1062e2"
   },
   "outputs": [],
   "source": [
    "# Taken from https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_of_emotions = list(f1_scores.keys())\n",
    "f1_score_values = list(f1_scores.values())\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.bar(list_of_emotions, f1_score_values, color ='blue', width = 0.6)\n",
    "plt.xlabel(\"Labels (emotions)\")\n",
    "plt.ylabel(\"F1 class score\")\n",
    "plt.title(\"F1 scores by class of svc classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(emotions_val, initial_classifier_results[\"svc\"][\"val\"][\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_classifier_results_binary[\"dummy_classifier_most_frequent\"] = fit_predict_and_score_classifier(dummy_classifier_most_frequent, *binary_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP12BrTLkY0A"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results_binary[\"dummy_classifier_stratified\"] = fit_predict_and_score_classifier(dummy_classifier_stratified, *binary_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFi7oHh1kqcF"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results_binary[\"logistic_regression\"] = fit_predict_and_score_classifier(logistic_regression, *binary_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiN0CnX2ktST"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results_binary[\"svc\"] = fit_predict_and_score_classifier(svc, *binary_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "68ytUVLHav6l",
    "outputId": "66b32dd9-2719-493c-8ac7-3261a8a4da8d"
   },
   "outputs": [],
   "source": [
    "initial_classifier_results_table_binary = create_result_table(initial_classifier_results_binary)\n",
    "display(initial_classifier_results_table_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XYuc7nRmNGd",
    "outputId": "7dc876a9-53df-4282-8600-0af2d9e98bbd"
   },
   "outputs": [],
   "source": [
    "f1_scores_binary = calculate_f1_scores_by_class(initial_classifier_results_binary[\"logistic_regression\"][\"val\"][\"predictions\"], emotions_binary_val)\n",
    "for emotion, score in f1_scores_binary.items():\n",
    "    print(f\"{emotion}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ZPCMAGy4opci",
    "outputId": "fab6fd7c-b687-4747-fc6b-db022f1062e2"
   },
   "outputs": [],
   "source": [
    "# Taken from https://www.geeksforgeeks.org/bar-plot-in-matplotlib/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_of_emotions_binary = list(f1_scores_binary.keys())\n",
    "f1_score_values_binary = list(f1_scores_binary.values())\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.bar(list_of_emotions_binary, f1_score_values_binary, color ='blue', width = 0.6)\n",
    "plt.xlabel(\"Labels (emotions)\")\n",
    "plt.ylabel(\"F1 class score\")\n",
    "plt.title(\"F1 scores by class of logistic_regression classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(emotions_binary_val, initial_classifier_results_binary[\"logistic_regression\"][\"val\"][\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treelib\n",
    "\n",
    "def add_node(tree, feature, is_feature):\n",
    "    feature_parent, delimiter, feature_name = feature.rpartition(\"_\")\n",
    "    \n",
    "    if not tree.contains(feature_parent):\n",
    "        add_node(tree, feature_parent, False)\n",
    "    \n",
    "    try:\n",
    "        tree.create_node(tag=feature_name, identifier=feature, parent=feature_parent, data=is_feature)\n",
    "    except treelib.exceptions.DuplicatedNodeIdError as error:\n",
    "        # Such node already exists, potentially because recursive parent creation created it before reaching the node itself\n",
    "        if is_feature:\n",
    "            feature_tree.get_node(feature).data = True\n",
    "\n",
    "feature_tree = treelib.Tree()\n",
    "\n",
    "feature_tree.create_node(tag=\"ROOT\", identifier=\"\", data=False)\n",
    "\n",
    "for column in speeches_train.columns:\n",
    "    add_node(feature_tree, column, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://medium.com/dive-into-ml-ai/tree-data-visualization-with-treelib-71633f6fd8fb\n",
    "import subprocess\n",
    "\n",
    "feature_tree.to_graphviz(\"Feature hierarchy graph description.dot\")\n",
    "subprocess.call([\"dot\", \"-Tsvg\", \"hello.dot\", \"-o\", \"Feature hierarchy graph.svg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_tree.all_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_endings = []\n",
    "analysis_by_endings = {}\n",
    "\n",
    "for column in speeches_train.columns:\n",
    "    feature_parent, delimiter, ending = column.rpartition(\"_\")\n",
    "    feature_endings.append(ending)\n",
    "    \n",
    "    if ending not in analysis_by_endings.keys():\n",
    "        analysis_by_endings[ending] = {\"features\": []}\n",
    "    \n",
    "    analysis_by_endings[ending][\"features\"].append(column)\n",
    "    \n",
    "print(Counter(feature_endings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature optimisation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_for_feature_optimisation = svc\n",
    "baseline_f1_score = initial_classifier_results[\"svc\"][\"val\"][\"F1\"]\n",
    "\n",
    "features_used_for_testing = 10_000 # 50 # 600\n",
    "\n",
    "speeches_train_copy = speeches_train.copy()\n",
    "speeches_train_copy.drop(speeches_train.columns[features_used_for_testing:], axis=1, inplace=True)\n",
    "speeches_val_copy = speeches_val.copy()\n",
    "speeches_val_copy.drop(speeches_val.columns[features_used_for_testing:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### Separated model to reduce time demands\n",
    "\n",
    "# from ipywidgets import IntProgress\n",
    "\n",
    "# # raise Exception(\"Prevent this cell from running so that it doesn't get stuck\")\n",
    "\n",
    "# endings_progress_bar = IntProgress(\n",
    "#     min=0,\n",
    "#     max=len(analysis_by_endings.keys())-1,\n",
    "#     description = f\"0/{len(analysis_by_endings)-1} ending\"\n",
    "# )\n",
    "\n",
    "# progress_bar = IntProgress(\n",
    "#     min=0,\n",
    "#     max=len(speeches_train_copy.columns)-1,\n",
    "#     description = f\"0th feature\"\n",
    "# )\n",
    "\n",
    "# inner_progress_bar = IntProgress(\n",
    "#     min=0,\n",
    "#     max=len(speeches_train.columns)-1,\n",
    "#     description = f\"0/{len(speeches_train_copy.columns)-1}\"\n",
    "# )\n",
    "\n",
    "# display(endings_progress_bar)\n",
    "# display(progress_bar)\n",
    "# display(inner_progress_bar)\n",
    "\n",
    "# for ending_index, data in enumerate(list(analysis_by_endings.values())):\n",
    "#     data[\"final_data_frame\"] = pd.DataFrame()\n",
    "#     data[\"removed_features\"] = []\n",
    "\n",
    "#     speeches_train_copy = speeches_train.copy()[data[\"features\"]]\n",
    "#     speeches_val_copy = speeches_val.copy()[data[\"features\"]]\n",
    "    \n",
    "#     progress_bar.value = 0\n",
    "#     progress_bar.max = len(speeches_train_copy.columns)-1\n",
    "#     inner_progress_bar.value = 0\n",
    "#     inner_progress_bar.max = len(speeches_train_copy.columns)-1\n",
    "#     endings_progress_bar.description = f\"{ending_index}/{len(analysis_by_endings)-1} ending\"\n",
    "    \n",
    "#     for feature_index in range(len(speeches_train_copy.columns)-1): # -1 so that the last feature is not deleted and an empty DataFrame is passed\n",
    "#         progress_bar.description = f\"{feature_index}/{len(speeches_train_copy.columns)-1} feature\"\n",
    "\n",
    "#         # Setting the new baseline\n",
    "#         result = fit_predict_and_score_classifier(\n",
    "#                 classifier_for_feature_optimisation,\n",
    "#                 speeches_train_copy,\n",
    "#                 speeches_val_copy, # speeches_val,\n",
    "#                 emotions_train,\n",
    "#                 emotions_val,\n",
    "#                 set(emotions)\n",
    "#             )\n",
    "#         max_f1_score = result[\"val\"][\"F1\"]\n",
    "#         column_to_remove = None\n",
    "\n",
    "#         # Finding the worst F1-reducing feature\n",
    "#         inner_progress_bar.max = len(speeches_train_copy.columns)\n",
    "#         inner_progress_bar.value = 0\n",
    "\n",
    "#         for index, column in enumerate(speeches_train_copy.columns):\n",
    "#             inner_progress_bar.description = f\"{index}/{len(speeches_train_copy.columns)-1}\"\n",
    "\n",
    "#             result = fit_predict_and_score_classifier(\n",
    "#                 classifier_for_feature_optimisation,\n",
    "#                 speeches_train_copy.drop([column], axis=1),\n",
    "#                 speeches_val_copy.drop([column], axis=1), # speeches_val.drop([column], axis=1),\n",
    "#                 emotions_train,\n",
    "#                 emotions_val,\n",
    "#                 set(emotions)\n",
    "#             )\n",
    "#             f1_score = result[\"val\"][\"F1\"]\n",
    "\n",
    "#             if f1_score > max_f1_score:\n",
    "#                 max_f1_score = f1_score\n",
    "#                 column_to_remove = column\n",
    "\n",
    "#             inner_progress_bar.value += 1\n",
    "\n",
    "#         # Removing the worst feature\n",
    "#         if column_to_remove is not None:\n",
    "#             speeches_train_copy.drop([column_to_remove], axis=1, inplace=True)\n",
    "#             speeches_val_copy.drop([column_to_remove], axis=1, inplace=True) # speeches_val.drop([column_to_remove], axis=1, inplace=True)\n",
    "#             data[\"removed_features\"].append((column_to_remove, max_f1_score, max_f1_score - f1_score))\n",
    "#             progress_bar.value += 1\n",
    "#         else:\n",
    "#             progress_bar.value = progress_bar.max\n",
    "#             inner_progress_bar.value = inner_progress_bar.max\n",
    "#             data[\"final_data_frame\"] = speeches_train_copy.copy()\n",
    "#             break\n",
    "            \n",
    "#     endings_progress_bar.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full version (slow but checking everything)\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "# raise Exception(\"Prevent this cell from running so that it doesn't get stuck\")\n",
    "\n",
    "progress_bar = IntProgress(\n",
    "    min=0,\n",
    "    max=len(speeches_train_copy.columns)-1,\n",
    "    description = f\"0th feature\"\n",
    ")\n",
    "\n",
    "inner_progress_bar = IntProgress(\n",
    "    min=0,\n",
    "    max=len(speeches_train.columns)-1,\n",
    "    description = f\"0/{len(speeches_train_copy.columns)-1}\"\n",
    ")\n",
    "\n",
    "display(progress_bar)\n",
    "display(inner_progress_bar)\n",
    "\n",
    "data = []\n",
    "final_data_frame = None\n",
    "# data[\"final_data_frame\"] = pd.DataFrame()\n",
    "# data[\"removed_features\"] = []\n",
    "\n",
    "speeches_train_copy = speeches_train.copy()\n",
    "speeches_val_copy = speeches_val.copy()\n",
    "\n",
    "progress_bar.value = 0\n",
    "progress_bar.max = len(speeches_train_copy.columns)-1\n",
    "inner_progress_bar.value = 0\n",
    "inner_progress_bar.max = len(speeches_train_copy.columns)-1\n",
    "\n",
    "for feature_index in range(len(speeches_train_copy.columns)-1): # -1 so that the last feature is not deleted and an empty DataFrame is passed\n",
    "    progress_bar.description = f\"{feature_index}/{len(speeches_train_copy.columns)-1} feature\"\n",
    "\n",
    "    # Setting the new baseline\n",
    "    result = fit_predict_and_score_classifier(\n",
    "            classifier_for_feature_optimisation,\n",
    "            speeches_train_copy,\n",
    "            speeches_val_copy, # speeches_val,\n",
    "            emotions_train,\n",
    "            emotions_val,\n",
    "            set(emotions)\n",
    "        )\n",
    "    max_f1_score = result[\"val\"][\"F1\"]\n",
    "    column_to_remove = None\n",
    "\n",
    "    # Finding the worst F1-reducing feature\n",
    "    inner_progress_bar.max = len(speeches_train_copy.columns)\n",
    "    inner_progress_bar.value = 0\n",
    "\n",
    "    for index, column in enumerate(speeches_train_copy.columns):\n",
    "        inner_progress_bar.description = f\"{index}/{len(speeches_train_copy.columns)-1}\"\n",
    "\n",
    "        result = fit_predict_and_score_classifier(\n",
    "            classifier_for_feature_optimisation,\n",
    "            speeches_train_copy.drop([column], axis=1),\n",
    "            speeches_val_copy.drop([column], axis=1), # speeches_val.drop([column], axis=1),\n",
    "            emotions_train,\n",
    "            emotions_val,\n",
    "            set(emotions)\n",
    "        )\n",
    "        f1_score = result[\"val\"][\"F1\"]\n",
    "\n",
    "        if f1_score > max_f1_score:\n",
    "            max_f1_score = f1_score\n",
    "            column_to_remove = column\n",
    "\n",
    "        inner_progress_bar.value += 1\n",
    "\n",
    "    # Removing the worst feature\n",
    "    if column_to_remove is not None:\n",
    "        speeches_train_copy.drop([column_to_remove], axis=1, inplace=True)\n",
    "        speeches_val_copy.drop([column_to_remove], axis=1, inplace=True) # speeches_val.drop([column_to_remove], axis=1, inplace=True)\n",
    "        data.append((column_to_remove, max_f1_score, max_f1_score - f1_score))\n",
    "        progress_bar.value += 1\n",
    "    else:\n",
    "        progress_bar.value = progress_bar.max\n",
    "        inner_progress_bar.value = inner_progress_bar.max\n",
    "        final_data_frame = speeches_train_copy.copy()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [entry[0] for entry in data]\n",
    "speeches_train_pruned = speeches_train.copy().drop(removed_columns, axis=1)\n",
    "speeches_val_pruned = speeches_val.copy().drop(removed_columns, axis=1)\n",
    "speeches_test_pruned = speeches_test.copy().drop(removed_columns, axis=1)\n",
    "\n",
    "multi_class_pruned_parameters = (speeches_train_pruned, speeches_val_pruned, emotions_train, emotions_val, set(emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(speeches_train.columns), len(speeches_train_pruned.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_classifier_results[\"svc_pruned\"] = fit_predict_and_score_classifier(svc, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_prunation_classifier_results_table = create_result_table(initial_classifier_results)\n",
    "display(post_prunation_classifier_results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_parameters = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.1, 1, 5, 10, 20, 50],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"shrinking\": [True, False],\n",
    "#     \"max_iter\": [-1, 100, 10_000],\n",
    "}\n",
    "\n",
    "parametrised_svc = GridSearchCV(svc, svc_parameters)\n",
    "parametrised_svc.fit(speeches_train_pruned, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parametrised_svc.cv_results_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_svc = parametrised_svc.best_estimator_\n",
    "optimised_parameters = parametrised_svc.best_params_\n",
    "optimised_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_classifier_results[\"svc_optimised\"] = fit_predict_and_score_classifier(optimised_svc, *multi_class_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_optimisation_classifier_results_table = create_result_table(initial_classifier_results)\n",
    "display(post_optimisation_classifier_results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "from sklearn import metrics\n",
    "\n",
    "def crop_audio(audio):\n",
    "    max_index = len(audio)-1\n",
    "    start = random.randint(0, max_index // 4)\n",
    "    end = random.randint(start * 2, max_index)\n",
    "    cropped_audio = audio[start:end]\n",
    "    return cropped_audio\n",
    "\n",
    "# Taken from https://medium.com/analytics-vidhya/adding-noise-to-audio-clips-5d8cee24ccb8\n",
    "def add_noise_to_audio(audio):\n",
    "    std = math.sqrt(np.mean(audio**2))\n",
    "    noise=np.random.normal(0, std, audio.shape[0])\n",
    "    signal_noise = audio + noise\n",
    "    return signal_noise\n",
    "\n",
    "# Taken from https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n",
    "def create_mel_spectrogram_file(spectrogram, sampling_rate, hop_length, index):\n",
    "    db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    librosa.display.specshow(db_spectrogram, sr=sampling_rate, hop_length=hop_length, x_axis=\"time\", y_axis=\"mel\");\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.savefig(f\"spectrograms/{index}_{emotions[index]}.png\")\n",
    "    plt.clf()\n",
    "    return spectrogram\n",
    "\n",
    "# Taken from https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n",
    "def produce_mel_spectrograms(files, hop_length=256, frameSize=512, n_mels=128):\n",
    "    spectrograms = []\n",
    "    emotions = []\n",
    "    max_audio_length = 0\n",
    "    audio_data = []\n",
    "    \n",
    "    for file in files:\n",
    "        audio, sampling_rate = librosa.load(file)\n",
    "        max_audio_length = max(max_audio_length, audio.shape[0])\n",
    "        emotion = file_name_to_emotion_mapping[file.split(\"-\")[-5]]\n",
    "        audio_data.append((audio, sampling_rate, emotion))\n",
    "    \n",
    "    for index, (audio, sampling_rate, emotion) in enumerate(audio_data):\n",
    "        audio = librosa.util.fix_length(audio, size=max_audio_length)\n",
    "        cropped_audio = crop_audio(audio)\n",
    "        noisy_audio = add_noise_to_audio(audio)\n",
    "        \n",
    "#         print(index)\n",
    "#         display(Audio(data=audio, rate=sampling_rate))\n",
    "#         display(Audio(data=cropped_audio, rate=sampling_rate))\n",
    "#         display(Audio(data=noisy_audio, rate=sampling_rate))\n",
    "        \n",
    "        for input_audio in [audio, noisy_audio]: ###### CROPPING TEMPORARILY REMOVED\n",
    "            spectrogram = librosa.feature.melspectrogram(y=audio, sr=sampling_rate, n_fft=frameSize, hop_length=hop_length, n_mels=n_mels)\n",
    "#             create_mel_spectrogram_file(spectrogram, sampling_rate, hop_length, index)\n",
    "\n",
    "            spectrograms.append(spectrogram)\n",
    "            emotions.append(emotion)\n",
    "\n",
    "    return np.array(spectrograms), np.array(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A rewrite to only modify training data\n",
    "\n",
    "# assert False\n",
    "\n",
    "# files_split, _ = perform_3_way_split(files, files, (80,10,10), SEED)\n",
    "# files_train, files_val, files_test = files_split\n",
    "\n",
    "# # But what to do with different length maximums? Hardcode a number?\n",
    "# # Add a is_train_set parameter to the function\n",
    "# spectrograms_train, spectrogram_emotions_train = produce_mel_spectrograms(files_train, True)\n",
    "# spectrograms_val, spectrogram_emotions_val = produce_mel_spectrograms(files_val, False)\n",
    "# spectrograms_test, spectrogram_emotions_test = produce_mel_spectrograms(files_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms, spectrogram_emotions = produce_mel_spectrograms(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(128, 455): 2880})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([s.shape for s in spectrograms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_spectrograms=(spectrograms-spectrograms.mean())/spectrograms.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_split, spectrogram_emotions_split = perform_3_way_split(normalised_spectrograms, spectrogram_emotions, (80,10,10), SEED)\n",
    "spectrograms_train, spectrograms_val, spectrograms_test = spectrograms_split\n",
    "spectrogram_emotions_train, spectrogram_emotions_val, spectrogram_emotions_test = spectrogram_emotions_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding single channel axes\n",
    "spectrograms_train = np.expand_dims(spectrograms_train, axis=1)\n",
    "spectrograms_val = np.expand_dims(spectrograms_val, axis=1)\n",
    "spectrograms_test = np.expand_dims(spectrograms_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_to_number_mapping = {emotion: int(number)-1 for number, emotion in file_name_to_emotion_mapping.items()}\n",
    "\n",
    "emotions_numeric_train = np.array([emotion_to_number_mapping[emotion] for emotion in spectrogram_emotions_train])\n",
    "emotions_numeric_val = np.array([emotion_to_number_mapping[emotion] for emotion in spectrogram_emotions_val])\n",
    "emotions_numeric_test = np.array([emotion_to_number_mapping[emotion] for emotion in spectrogram_emotions_test])\n",
    "\n",
    "spectrogram_emotions_binary_train = np.array([emotion_to_positivity_mapping[emotion] for emotion in spectrogram_emotions_train])\n",
    "spectrogram_emotions_binary_val = np.array([emotion_to_positivity_mapping[emotion] for emotion in spectrogram_emotions_val])\n",
    "spectrogram_emotions_binary_test = np.array([emotion_to_positivity_mapping[emotion] for emotion in spectrogram_emotions_test])\n",
    "\n",
    "emotions_numeric_binary_train = np.array([1 if emotion == \"positive\" else 0 for emotion in spectrogram_emotions_binary_train])\n",
    "emotions_numeric_binary_val = np.array([1 if emotion == \"positive\" else 0 for emotion in spectrogram_emotions_binary_val])\n",
    "emotions_numeric_binary_test = np.array([1 if emotion == \"positive\" else 0 for emotion in spectrogram_emotions_binary_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.6918\n",
      "0.007817257\n"
     ]
    }
   ],
   "source": [
    "print(np.max(spectrograms))\n",
    "print(np.mean(spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 1, 128, 455)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_binary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_tensor_train = torch.from_numpy(spectrograms_train).float()\n",
    "spectrograms_tensor_val = torch.from_numpy(spectrograms_val).float()\n",
    "spectrograms_tensor_test = torch.from_numpy(spectrograms_test).float()\n",
    "\n",
    "if use_binary is False:\n",
    "    emotions_tensor_train = torch.from_numpy(emotions_numeric_train).long()\n",
    "    emotions_tensor_val = torch.from_numpy(emotions_numeric_val).long()\n",
    "    emotions_tensor_test = torch.from_numpy(emotions_numeric_test).long()\n",
    "else:\n",
    "    emotions_tensor_train = torch.from_numpy(emotions_numeric_binary_train).long()\n",
    "    emotions_tensor_val = torch.from_numpy(emotions_numeric_binary_val).long()\n",
    "    emotions_tensor_test = torch.from_numpy(emotions_numeric_binary_test).long()\n",
    "\n",
    "spectrograms_tensor_train.to(device)\n",
    "spectrograms_tensor_val.to(device)\n",
    "spectrograms_tensor_test.to(device)\n",
    "\n",
    "emotions_tensor_train.to(device)\n",
    "emotions_tensor_val.to(device)\n",
    "emotions_tensor_test.to(device)\n",
    "\n",
    "spectrogram_dimensions = spectrograms_tensor_train.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 1, 128, 455])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms_tensor_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_dataset_train = torch.utils.data.TensorDataset(spectrograms_tensor_train, emotions_tensor_train)\n",
    "spectrogram_dataset_val = torch.utils.data.TensorDataset(spectrograms_tensor_val, emotions_tensor_val)\n",
    "\n",
    "spectrogram_loader_train = torch.utils.data.DataLoader(spectrogram_dataset_train, batch_size=4, shuffle=True)\n",
    "spectrogram_loader_val = torch.utils.data.DataLoader(spectrogram_dataset_val, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_binary is False:\n",
    "    number_to_emotion_mapping = {int(file_name)-1: emotion for file_name, emotion in file_name_to_emotion_mapping.items()}\n",
    "else:\n",
    "    number_to_emotion_mapping = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyTorch example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "example_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "example_training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=example_transform)\n",
    "example_validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=example_transform)\n",
    "\n",
    "example_training_loader = torch.utils.data.DataLoader(example_training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "example_validation_loader = torch.utils.data.DataLoader(example_validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram_loader_train = example_training_loader\n",
    "# spectrogram_loader_val = example_validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layered Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spectrograms as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSpectrogramModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PerceptronSpectrogramModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(np.prod(spectrogram_dimensions), 10)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(10, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 128 455]\n",
      "[  1  29 110]\n",
      "3190\n"
     ]
    }
   ],
   "source": [
    "convoluted_dimensions = np.array(spectrogram_dimensions)\n",
    "print(convoluted_dimensions)\n",
    "convoluted_dimensions -= (3 - 1)\n",
    "convoluted_dimensions -= (3 - 1)\n",
    "convoluted_dimensions //= 2\n",
    "convoluted_dimensions -= (3 - 1)\n",
    "convoluted_dimensions -= (3 - 1)\n",
    "convoluted_dimensions //= 2\n",
    "convoluted_dimensions[0] = 1\n",
    "print(convoluted_dimensions)\n",
    "print(np.prod(convoluted_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_binary is False:\n",
    "    class_count = len(set(emotions))\n",
    "else:\n",
    "    class_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, 3)\n",
    "        self.conv2 = torch.nn.Conv2d(4, 8, 3)\n",
    "        self.conv3 = torch.nn.Conv2d(8, 16, 3)\n",
    "        self.conv4 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.fc1 = torch.nn.Linear(16 * np.prod(convoluted_dimensions), 32)\n",
    "        self.fc2 = torch.nn.Linear(32, class_count)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ExampleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of CNN(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=51040, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = PerceptronSpectrogramModel()\n",
    "model = CNN()\n",
    "# model = ExampleNet()\n",
    "model = model.to(device)\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) #### TEMPORARILY INCRESEAD FOR QUICKER RUNTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially to delete, but should fix TensorBoard problems\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, inputs, labels):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    output_predictions = torch.nn.Softmax(dim=1)(outputs).argmax(1)\n",
    "    correct_count = torch.sum((output_predictions == labels)).item()\n",
    "    accuracy = correct_count/len(labels)\n",
    "    return accuracy\n",
    "\n",
    "# Taken from https://stackoverflow.com/questions/39770376/scikit-learn-get-accuracy-scores-for-each-class\n",
    "def calculate_class_accuracy(model, inputs, labels):\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    output_predictions = torch.nn.Softmax(dim=1)(outputs).argmax(1)\n",
    "    output_predictions = output_predictions.to(\"cpu\")\n",
    "    output_emotions = np.array([number_to_emotion_mapping[value] for value in output_predictions.to(\"cpu\").numpy()])\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(output_predictions, labels)\n",
    "    confusion_matrix = np.nan_to_num(confusion_matrix)\n",
    "    guess_counts = np.clip(confusion_matrix.sum(axis=1), 1, None) # Set minimum to 0 to avoid division by 0\n",
    "#     print(50*\"\")\n",
    "#     print(confusion_matrix.diagonal())\n",
    "#     print(guess_counts)\n",
    "#     print(50*\"\")\n",
    "    class_accuracy = confusion_matrix.diagonal() / guess_counts\n",
    "    \n",
    "    if use_binary is False:\n",
    "        label_set = metrics.ConfusionMatrixDisplay.from_predictions(spectrogram_emotions_val, output_emotions).display_labels\n",
    "    else:\n",
    "        label_set = metrics.ConfusionMatrixDisplay.from_predictions(spectrogram_emotions_binary_val, output_emotions).display_labels\n",
    "    \n",
    "    plt.close()\n",
    "    class_accuracy_dict = {label: accuracy for label, accuracy in zip(label_set, class_accuracy)}\n",
    "    \n",
    "    return class_accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(spectrogram_loader_train):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 32 == 31:\n",
    "            last_loss = running_loss / 32 # loss per batch\n",
    "# #             print(f\"  batch {i + 1} loss: {last_loss:.4f} acc: {last_accuracy:.4f}\")\n",
    "#             tb_x = epoch_index * len(spectrogram_loader_train) + i + 1\n",
    "#             tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "        elif i == len(spectrogram_loader_train)-1:\n",
    "            last_loss = running_loss / (len(spectrogram_loader_train) % 32) # loss per batch\n",
    "# #             print(f\"  batch {i + 1} loss: {last_loss:.4f} acc: {last_accuracy:.4f}\")\n",
    "#             tb_x = epoch_index * len(spectrogram_loader_train) + i + 1\n",
    "#             tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    accuracy = calculate_accuracy(model, spectrograms_tensor_train, emotions_tensor_train)\n",
    "    \n",
    "    return last_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "\t LOSS train 1.8058 valid 1.7569 \t\t ACC train 0.2743 valid 0.2778\n",
      "\t PER-CLASS ACC valid {'angry': 0.0, 'calm': 0.06382978723404255, 'disgust': 0.6666666666666666, 'fearful': 0.2152777777777778, 'happy': 0.43333333333333335, 'neutral': 0.6111111111111112, 'sad': 0.7142857142857143, 'surprised': 0.2222222222222222}\n",
      "EPOCH 2:\n",
      "\t LOSS train 1.6833 valid 1.6455 \t\t ACC train 0.4379 valid 0.3507\n",
      "\t PER-CLASS ACC valid {'angry': 0.0, 'calm': 0.26515151515151514, 'disgust': 0.28, 'fearful': 0.20588235294117646, 'happy': 0.575, 'neutral': 0.6875, 'sad': 0.5333333333333333, 'surprised': 0.38461538461538464}\n",
      "EPOCH 3:\n",
      "\t LOSS train 1.5060 valid 1.6225 \t\t ACC train 0.4601 valid 0.4028\n",
      "\t PER-CLASS ACC valid {'angry': 0.0, 'calm': 0.40625, 'disgust': 0.3333333333333333, 'fearful': 0.2222222222222222, 'happy': 0.8518518518518519, 'neutral': 0.5, 'sad': 0.4878048780487805, 'surprised': 0.5294117647058824}\n",
      "EPOCH 4:\n",
      "\t LOSS train 1.2879 valid 1.6766 \t\t ACC train 0.5560 valid 0.4549\n",
      "\t PER-CLASS ACC valid {'angry': 0.0, 'calm': 0.35802469135802467, 'disgust': 0.48, 'fearful': 0.3333333333333333, 'happy': 0.7027027027027027, 'neutral': 0.7619047619047619, 'sad': 0.43478260869565216, 'surprised': 0.36666666666666664}\n",
      "EPOCH 5:\n",
      "\t LOSS train 1.2052 valid 1.8261 \t\t ACC train 0.5951 valid 0.5069\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.38461538461538464, 'disgust': 0.6666666666666666, 'fearful': 0.3333333333333333, 'happy': 0.7142857142857143, 'neutral': 0.6666666666666666, 'sad': 0.6060606060606061, 'surprised': 0.5111111111111111}\n",
      "EPOCH 6:\n",
      "\t LOSS train 0.8942 valid 1.9315 \t\t ACC train 0.6536 valid 0.5556\n",
      "\t PER-CLASS ACC valid {'angry': 0.5, 'calm': 0.4791666666666667, 'disgust': 0.46296296296296297, 'fearful': 0.38461538461538464, 'happy': 0.7837837837837838, 'neutral': 0.9166666666666666, 'sad': 0.65, 'surprised': 0.5853658536585366}\n",
      "EPOCH 7:\n",
      "\t LOSS train 0.9738 valid 1.5312 \t\t ACC train 0.7122 valid 0.5625\n",
      "\t PER-CLASS ACC valid {'angry': 0.3333333333333333, 'calm': 0.52, 'disgust': 0.5588235294117647, 'fearful': 0.36507936507936506, 'happy': 0.8235294117647058, 'neutral': 0.7142857142857143, 'sad': 0.574468085106383, 'surprised': 0.7}\n",
      "EPOCH 8:\n",
      "\t LOSS train 0.7487 valid 1.7817 \t\t ACC train 0.7496 valid 0.6389\n",
      "\t PER-CLASS ACC valid {'angry': 0.5833333333333334, 'calm': 0.4626865671641791, 'disgust': 0.875, 'fearful': 0.4423076923076923, 'happy': 0.8421052631578947, 'neutral': 0.7619047619047619, 'sad': 0.675, 'surprised': 0.7941176470588235}\n",
      "EPOCH 9:\n",
      "\t LOSS train 1.0961 valid 1.6892 \t\t ACC train 0.7765 valid 0.6562\n",
      "\t PER-CLASS ACC valid {'angry': 0.5, 'calm': 0.5769230769230769, 'disgust': 0.7352941176470589, 'fearful': 0.4897959183673469, 'happy': 0.875, 'neutral': 0.9411764705882353, 'sad': 0.6666666666666666, 'surprised': 0.6590909090909091}\n",
      "EPOCH 10:\n",
      "\t LOSS train 0.5544 valid 2.0136 \t\t ACC train 0.8242 valid 0.6840\n",
      "\t PER-CLASS ACC valid {'angry': 0.42857142857142855, 'calm': 0.574468085106383, 'disgust': 0.7714285714285715, 'fearful': 0.5555555555555556, 'happy': 0.7804878048780488, 'neutral': 0.7931034482758621, 'sad': 0.6666666666666666, 'surprised': 0.8529411764705882}\n",
      "EPOCH 11:\n",
      "\t LOSS train 0.5704 valid 2.5100 \t\t ACC train 0.8420 valid 0.7188\n",
      "\t PER-CLASS ACC valid {'angry': 0.55, 'calm': 0.5957446808510638, 'disgust': 0.8157894736842105, 'fearful': 0.5531914893617021, 'happy': 0.825, 'neutral': 0.9473684210526315, 'sad': 0.7380952380952381, 'surprised': 0.8285714285714286}\n",
      "EPOCH 12:\n",
      "\t LOSS train 0.3637 valid 2.8083 \t\t ACC train 0.8772 valid 0.7465\n",
      "\t PER-CLASS ACC valid {'angry': 0.4642857142857143, 'calm': 0.6666666666666666, 'disgust': 0.8857142857142857, 'fearful': 0.6363636363636364, 'happy': 0.7619047619047619, 'neutral': 0.9523809523809523, 'sad': 0.8823529411764706, 'surprised': 0.7777777777777778}\n",
      "EPOCH 13:\n",
      "\t LOSS train 0.3709 valid 2.4551 \t\t ACC train 0.8459 valid 0.7188\n",
      "\t PER-CLASS ACC valid {'angry': 0.8571428571428571, 'calm': 0.64, 'disgust': 0.7560975609756098, 'fearful': 0.4918032786885246, 'happy': 0.8378378378378378, 'neutral': 0.84, 'sad': 0.7837837837837838, 'surprised': 0.9}\n",
      "EPOCH 14:\n",
      "\t LOSS train 0.4757 valid 2.9063 \t\t ACC train 0.8989 valid 0.7500\n",
      "\t PER-CLASS ACC valid {'angry': 0.5454545454545454, 'calm': 0.7368421052631579, 'disgust': 0.90625, 'fearful': 0.5517241379310345, 'happy': 0.8888888888888888, 'neutral': 0.8636363636363636, 'sad': 0.8378378378378378, 'surprised': 0.7674418604651163}\n",
      "EPOCH 15:\n",
      "\t LOSS train 0.3069 valid 1.3687 \t\t ACC train 0.9032 valid 0.7743\n",
      "\t PER-CLASS ACC valid {'angry': 0.5909090909090909, 'calm': 0.6444444444444445, 'disgust': 0.8205128205128205, 'fearful': 0.7142857142857143, 'happy': 0.8857142857142857, 'neutral': 0.92, 'sad': 0.8536585365853658, 'surprised': 0.7692307692307693}\n",
      "EPOCH 16:\n",
      "\t LOSS train 0.3045 valid 1.6416 \t\t ACC train 0.9253 valid 0.7951\n",
      "\t PER-CLASS ACC valid {'angry': 0.7647058823529411, 'calm': 0.6595744680851063, 'disgust': 0.868421052631579, 'fearful': 0.6744186046511628, 'happy': 0.8888888888888888, 'neutral': 0.96, 'sad': 0.85, 'surprised': 0.7857142857142857}\n",
      "EPOCH 17:\n",
      "\t LOSS train 0.1601 valid 1.3820 \t\t ACC train 0.9280 valid 0.8229\n",
      "\t PER-CLASS ACC valid {'angry': 0.7647058823529411, 'calm': 0.6739130434782609, 'disgust': 0.9696969696969697, 'fearful': 0.7111111111111111, 'happy': 0.8918918918918919, 'neutral': 0.896551724137931, 'sad': 0.9, 'surprised': 0.8292682926829268}\n",
      "EPOCH 18:\n",
      "\t LOSS train 0.1897 valid 1.7558 \t\t ACC train 0.9384 valid 0.8021\n",
      "\t PER-CLASS ACC valid {'angry': 0.7058823529411765, 'calm': 0.7142857142857143, 'disgust': 0.8717948717948718, 'fearful': 0.7073170731707317, 'happy': 0.8648648648648649, 'neutral': 1.0, 'sad': 0.813953488372093, 'surprised': 0.7777777777777778}\n",
      "EPOCH 19:\n",
      "\t LOSS train 0.1186 valid 1.8664 \t\t ACC train 0.9392 valid 0.8264\n",
      "\t PER-CLASS ACC valid {'angry': 0.8235294117647058, 'calm': 0.6875, 'disgust': 0.9714285714285714, 'fearful': 0.6666666666666666, 'happy': 0.8857142857142857, 'neutral': 1.0, 'sad': 0.8571428571428571, 'surprised': 0.8536585365853658}\n",
      "EPOCH 20:\n",
      "\t LOSS train 0.1879 valid 2.3407 \t\t ACC train 0.9505 valid 0.8194\n",
      "\t PER-CLASS ACC valid {'angry': 0.875, 'calm': 0.7380952380952381, 'disgust': 0.868421052631579, 'fearful': 0.6818181818181818, 'happy': 0.8888888888888888, 'neutral': 0.9259259259259259, 'sad': 0.8181818181818182, 'surprised': 0.8536585365853658}\n",
      "EPOCH 21:\n",
      "\t LOSS train 0.1385 valid 1.8251 \t\t ACC train 0.9405 valid 0.8229\n",
      "\t PER-CLASS ACC valid {'angry': 0.75, 'calm': 0.75, 'disgust': 0.9411764705882353, 'fearful': 0.7441860465116279, 'happy': 0.8421052631578947, 'neutral': 0.96, 'sad': 0.813953488372093, 'surprised': 0.8292682926829268}\n",
      "EPOCH 22:\n",
      "\t LOSS train 0.4880 valid 1.8714 \t\t ACC train 0.9236 valid 0.7917\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.68, 'disgust': 0.7692307692307693, 'fearful': 0.6170212765957447, 'happy': 0.90625, 'neutral': 0.96, 'sad': 0.8409090909090909, 'surprised': 0.85}\n",
      "EPOCH 23:\n",
      "\t LOSS train 0.1000 valid 1.5085 \t\t ACC train 0.9614 valid 0.8750\n",
      "\t PER-CLASS ACC valid {'angry': 0.75, 'calm': 0.868421052631579, 'disgust': 0.8536585365853658, 'fearful': 0.868421052631579, 'happy': 0.8918918918918919, 'neutral': 1.0, 'sad': 0.9024390243902439, 'surprised': 0.8571428571428571}\n",
      "EPOCH 24:\n",
      "\t LOSS train 0.0648 valid 1.6254 \t\t ACC train 0.9670 valid 0.8750\n",
      "\t PER-CLASS ACC valid {'angry': 0.9333333333333333, 'calm': 0.7727272727272727, 'disgust': 0.875, 'fearful': 0.8095238095238095, 'happy': 0.9444444444444444, 'neutral': 1.0, 'sad': 0.9024390243902439, 'surprised': 0.8571428571428571}\n",
      "EPOCH 25:\n",
      "\t LOSS train 0.2317 valid 2.5812 \t\t ACC train 0.9388 valid 0.8299\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.7333333333333333, 'disgust': 0.868421052631579, 'fearful': 0.7804878048780488, 'happy': 0.9090909090909091, 'neutral': 0.8666666666666667, 'sad': 0.76, 'surprised': 0.9}\n",
      "EPOCH 26:\n",
      "\t LOSS train 0.7052 valid 2.7196 \t\t ACC train 0.8312 valid 0.7188\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.8611111111111112, 'disgust': 0.8214285714285714, 'fearful': 0.6078431372549019, 'happy': 0.875, 'neutral': 0.42424242424242425, 'sad': 0.825, 'surprised': 0.9230769230769231}\n",
      "EPOCH 27:\n",
      "\t LOSS train 0.1494 valid 1.3536 \t\t ACC train 0.9679 valid 0.8646\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.7727272727272727, 'disgust': 0.9459459459459459, 'fearful': 0.6938775510204082, 'happy': 0.9142857142857143, 'neutral': 1.0, 'sad': 0.9, 'surprised': 0.8780487804878049}\n",
      "EPOCH 28:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t LOSS train 0.0733 valid 1.5805 \t\t ACC train 0.9696 valid 0.8785\n",
      "\t PER-CLASS ACC valid {'angry': 0.782608695652174, 'calm': 0.8292682926829268, 'disgust': 0.8974358974358975, 'fearful': 0.8918918918918919, 'happy': 0.9142857142857143, 'neutral': 1.0, 'sad': 0.9024390243902439, 'surprised': 0.8222222222222222}\n",
      "EPOCH 29:\n",
      "\t LOSS train 0.0825 valid 1.6667 \t\t ACC train 0.9748 valid 0.8785\n",
      "\t PER-CLASS ACC valid {'angry': 1.0, 'calm': 0.7906976744186046, 'disgust': 0.9459459459459459, 'fearful': 0.7446808510638298, 'happy': 0.9411764705882353, 'neutral': 1.0, 'sad': 0.925, 'surprised': 0.8409090909090909}\n",
      "EPOCH 30:\n",
      "\t LOSS train 0.0814 valid 1.8050 \t\t ACC train 0.9813 valid 0.8785\n",
      "\t PER-CLASS ACC valid {'angry': 0.8888888888888888, 'calm': 0.8095238095238095, 'disgust': 0.875, 'fearful': 0.825, 'happy': 0.8536585365853658, 'neutral': 1.0, 'sad': 0.8780487804878049, 'surprised': 0.9473684210526315}\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(f\"runs/model_{timestamp}\")\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch + 1}:\")\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss, accuracy_train = train_one_epoch(epoch, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(spectrogram_loader_val):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            \n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    \n",
    "    accuracy_val = calculate_accuracy(model, spectrograms_tensor_val, emotions_tensor_val)\n",
    "    class_accuracy_val = calculate_class_accuracy(model, spectrograms_tensor_val, emotions_tensor_val)\n",
    "    \n",
    "    print(f\"\\t LOSS train {avg_loss:.4f} valid {avg_vloss:.4f} \\t\\t ACC train {accuracy_train:.4f} valid {accuracy_val:.4f}\")\n",
    "    print(f\"\\t PER-CLASS ACC valid {class_accuracy_val}\")\n",
    "    \n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars(\n",
    "        \"Training vs. Validation Loss\",\n",
    "        {\"Training\" : avg_loss, \"Validation\" : avg_vloss},\n",
    "        epoch + 1,\n",
    "    )\n",
    "    \n",
    "    writer.add_scalars(\n",
    "        \"Training vs. Validation Accuracy\",\n",
    "        {\"Training\" : accuracy_train, \"Validation\" : accuracy_val},\n",
    "        epoch + 1,\n",
    "    )\n",
    "    \n",
    "    writer.add_scalars(\n",
    "        \"Class accuracy\",\n",
    "        class_accuracy_val,\n",
    "        epoch + 1,\n",
    "    )\n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f\"model_checkpoints/model_{timestamp}_{epoch}\"\n",
    "#         torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_outputs = model(spectrograms_tensor_val.to(device))\n",
    "validation_output_predictions = torch.nn.Softmax(dim=1)(validation_outputs).argmax(1)\n",
    "validation_output_emotions = np.array([number_to_emotion_mapping[value] for value in validation_output_predictions.to(\"cpu\").numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_binary is False:\n",
    "    model_confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(spectrogram_emotions_val, validation_output_emotions)\n",
    "else:\n",
    "    model_confusion_matrix = metrics.ConfusionMatrixDisplay.from_predictions(spectrogram_emotions_binary_val, validation_output_emotions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf ./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "89Q5h1M-iGtX",
    "AB0Y6xS17Tj3",
    "aikqCd3d7b6d",
    "GTMFgODnbDsI",
    "I9mj2L3jiGtl",
    "foKQaWCiUpRh",
    "gVSMGXRVz0Mn",
    "RgQbyZBBb5mm",
    "vJPQreO0cByU",
    "d8eXs9T1fGFe",
    "Dt8wYLwhkUPl",
    "GxOlNT22khAD",
    "dMxfsKiXAicT"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
